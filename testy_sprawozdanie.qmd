---
title: "Sprawozdanie 2"
author: "Konrad Słotta i Kacper Łazurkiewicz"
format: pdf
editor: visual
execute:
  echo: false
---

# Przyjęte założenia i hipotezy

Rozważamy testy na poziomie istotności $\alpha = 0.05$ do testowania

-   $H_0: p = 0.1$, przeciwko

-   $H_1: p < 0.1$.

Będziemy wykonywać sprawdzenie tej hipotezy, stosując wprost trzy testy:

1.  testu opartego o przedział Wilsona,

2.  testu opartego o przedział Cloppera-Pearsona,

3.  testu opartego o przedział Jeffreysa.

Testy te będziemy rozważać na próbkach z rozkładu Bernoulliego $S \sim \mathcal{B}(n, p)$. Estymator prawdopodobieństwa $p$ definiujemy przez stosunek liczby sukcesów do liczby prób, zatem
$$
\hat{p} = \frac{S}{n}.
$$
Dodatkowo z rozkładu wiemy, że
$$
\mathbb{E}(\hat{p}) = p, \quad \text{Var}(\hat{p}) = \frac{p(1-p)}{n}
$$
Do obliczania przedziałów ufności w R użyjemy funkcji BinomCI z pakietu DescTools.

### Przedział Wilsona
Przedział Wilsona oparty jest na normalnym przybliżeniu rozkładu Bernoulliego tzn.
$$
\frac{\hat{p}-\mathbb{E}(\hat{p})}{\sqrt{\text{Var}(\hat{p})}} \approx \mathcal{N}(0, 1) \iff
\frac{\hat{p}-p}{\sqrt{p(1-p)/n}} \approx \mathcal{N}(0, 1).
$$
Dla przedziału lewostronnego mamy:
$$
\mathbb{P}\left(\frac{\hat{p}-p}{\sqrt{p(1-p)/n}} \geq -z_{1-\alpha}\right) \approx 1 - \alpha.
$$

Lewostronny przedział Wilsona otrzymujemy rozwiązując nierówność dla $p$
$$
 \frac{\hat{p}-p}{\sqrt{p(1-p)/n}} \geq -z_{1-\alpha}
$$
Rozwiązując nierówność otrzymujemy przedział ufności $(0, U_W]$, gdzie
$$
 U_W = \frac{1}{1+ \frac{z_{1-\alpha}^2}{n}}\left(\hat{p}+\frac{z_{1-\alpha}^2}{2n} + z_{1-\alpha}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}+\frac{z_{1-\alpha}^2}{4n^2}}\right)
$$
Odrzucamy hipotezę zerową $H_0$, jeżeli $0.1 \notin (0, U_W]$ lub równoważnie $0.1 > U_W$.

### Przedział Cloppera-Pearsona
Przedział Cloppera-Pearsona oparty jest o dystrybuantę $S \sim \mathcal{B}(n, p)$, która opisana jest równaniem
$$
\mathbb{P}(S \leq s) = \sum_{k=0}^s \binom{n}{k}p^k(1-p)^{n-k},
$$
gdzie $s$ to liczba sukcesów w obserwowanej próbie. Dla przedziału lewostronnego $(0, U_{CP}]$ szukamy $U_{CP}$ spełniającego
$$
\mathbb{P}_{p=U_{CP}}(S\leq s) = 1 - \alpha,
$$
zatem górna granica $U_{CP}$ przedziału ufności  jest rozwiązaniem równania
$$
\sum_{k=0}^s \binom{n}{k}(U_{CP})^k(1-U_{CP})^{n-k} = 1 - \alpha.
$$
Alternatywnie, korzystając z relacji między rozkładem Bernoulliego a rozkładem beta przedział Cloppera-Pearsona możemy zdefiniować za pomocą kwantyli rozkładu beta, wtedy
$$
U_{CP} = \text{Beta}^{-1}(1-\alpha; s+1; n-s),
$$
gdzie $\text{Beta}^{-1}$ oznacza kwantyl rozkładu beta. Odrzucamy hipotezę zerową $H_0$, jeżeli $0.1 \notin (0, U_{CP}]$ lub równoważnie $0.1 > U_{CP}$.

### Przedział Jeffreysa
Przedział Jeffreysa oparty jest o rozkład Jeffreysa. W przypadku próby z rozkładu Bernoulliego $S \sim \mathcal{B}(n, p)$ zakładamy, że prawdopodobieństwo $p$ ma rozkład 
$$
p \sim \text{Beta}\left(\frac{1}{2}, \frac{1}{2}\right).
$$
Po zaobserwowaniu w próbie $s$ sukcesów rozkład prawdopodobieństwa wygląda następująco
$$
p | s \sim \text{Beta}\left(s+\frac{1}{2}, n - s + \frac{1}{2}  \right).
$$
Lewostronny przedział ufności $(0, U_J)$ otrzymamy obliczając kwantyl $1-\alpha$ powyższego rozkładu, zatem
$$
U_J = \text{Beta}^{-1}\left(1-\alpha, s+\frac{1}{2}, n - s + \frac{1}{2}  \right).
$$
Odrzucamy hipotezę zerową $H_0$, jeżeli $0.1 \notin (0, U_{J}]$ lub równoważnie $0.1 > U_{J}$.

### Test jednostajnie najmocniejszy
Przeprowadzany przez nas test jest niezrandomizowany, zatem funkcję mocy definiujemy następująco
$$
\beta_T(p) = \mathbb{P}_p[T(S) = 1],
$$
gdzie $T$ oznacza przeprowadzany test.

Test jest jednostajnie najmocniejszy w danej rodzinie testów przy poziomie istotności $\alpha$, jeśli jest mocniejszy lub niegorszy od dowolnego innego rozważanego testu dla wszystkich wartości zbioru hipotezy alternatywnej, czyli w naszym przypadku dla $p < 0.1$. Inaczej, test $T^*$ jest jednostajnie najmocniejszy w rodzinie testów $\mathcal{T}_\alpha$, jeżeli 
$$
\forall_{p < 0.1}\forall_{T\in\mathcal{T}_\alpha}\beta_{T^*}(p) \geq \beta_T(p).
$$

# Przeprowadzenie testów
```{r}
library(DescTools)

alpha <- 0.05
Nmc   <- 1000
P_seq <- seq(0,1,0.001)

power <- function(n,P=P_seq){
  
  power_wilson <- sapply(P,function(p) {
    S <- rbinom(Nmc, size = n, prob = p)
    mean(sapply(S, function(s) {
      ci <- BinomCI(x = s, n = n, conf.level = 1-alpha, method="wilson")
      ci[,3] < 0.1
    }))
  })
  
  power_cp <- sapply(P, function(p) {
    S <- rbinom(Nmc, size = n, prob = p)
    mean(sapply(S, function(s) {
      ci <- BinomCI(x = s, n = n, conf.level = 1-alpha, method="clopper-pearson")
      ci[,3] < 0.1
    }))
  })
  
  power_jeff <- sapply(P, function(p) {
    S <- rbinom(Nmc, size = n, prob = p)
    mean(sapply(S, function(s) {
      ci <- BinomCI(x = s, n = n, conf.level = 1-alpha, method="jeffreys")
      ci[,3] < 0.1
    }))
  })
  
  list(P = P, power_wilson = power_wilson,
       power_cp = power_cp, power_jeff = power_jeff)
}

draw_power <- function(power_n, zoomx = c(0,1), zoomy = FALSE, alpha = 0.05) {
  
  idx <- (power_n$P >= zoomx[1]) & (power_n$P <= zoomx[2])
  P <- power_n$P[idx]
  power_wilson <- power_n$power_wilson[idx]
  power_cp     <- power_n$power_cp[idx]
  power_jeff   <- power_n$power_jeff[idx]
  
  ylim_range <- if(zoomy) c(0, 2*alpha) else c(0,1)

  main_text <- sprintf("Funkcje mocy (zoomx = [%.2f, %.2f], zoomy = %s)", 
                       zoomx[1], zoomx[2], zoomy)
  
  plot(P, power_wilson, type="l", lwd=2, lty=1, col="black",
       ylim=ylim_range, xlab="p", ylab="Moc testu",
       main=main_text, cex.main=1, adj=0.5)
  
  lines(P, power_cp, col="red", lwd=2, lty=2)
  lines(P, power_jeff, col="blue", lwd=2, lty=4)
  
  abline(v=0.1, lty=3, col="darkgrey")  # H0
  abline(h=alpha, lty=3, col="grey")    # poziom istotności
  
  legend("topright",
         legend=c("Wilson","Clopper-Pearson","Jeffreys"),
         col=c("black","red","blue"),
         lwd=2, lty=c(1,2,4))
}


kompilacja <- FALSE
wczytanie <- TRUE
zapis <- FALSE

if(kompilacja){
  power1 <- power(5)
  power2 <- power(30)
  power3 <- power(250)
}
if(zapis&kompilacja){
  save(power1, file = "wyniki1_MC.RData")
  save(power2, file = "wyniki2_MC.RData")
  save(power3, file = "wyniki3_MC.RData")
}
if(wczytanie){
  load("wyniki1_MC.RData")
  load("wyniki2_MC.RData")
  load("wyniki3_MC.RData")
}
```
### Testy dla $S \sim \mathcal{B}(5, p)$
```{r}
#| fig-width: 7
#| fig-height: 6
draw_power(power1, zoomx=c(0,1),zoomy=TRUE)
```
### Testy dla $S \sim \mathcal{B}(30, p)$
```{r}
#| fig-width: 7
#| fig-height: 6
draw_power(power2, zoomx=c(0,1),zoomy=FALSE)
draw_power(power2, zoomx=c(0,0.25),zoomy=FALSE)
draw_power(power2, zoomx=c(0,0.25),zoomy=TRUE)
```

### Testy dla $S \sim \mathcal{B}(250, p)$
```{r}
#| fig-width: 7
#| fig-height: 6
draw_power(power3, zoomx=c(0,1),zoomy=FALSE)
draw_power(power3, zoomx=c(0.08,0.15),zoomy=FALSE)
draw_power(power3, zoomx=c(0.08,0.15),zoomy=TRUE)
```
# Podsumowanie
