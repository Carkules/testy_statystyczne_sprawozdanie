---
title: "Sprawozdanie 2"
author: "Konrad Słotta i Kacper Łazurkiewicz"
format: pdf
editor: visual
---

# Przyjęte założenia i hipotezy

Rozważamy testy na poziomie istotności $\alpha = 0.05$ do testowania

-   $H_0: p = 0.1$, przeciwko

-   $H_1: p < 0.1$.

Będziemy wykonywać sprawdzenie tej hipotezy, stosując wprost trzy testy:

1.  testu opartego o przedział Wilsona,

2.  testu opartego o przedział Cloppera-Pearsona,

3.  testu opartego o przedział Jeffreysa.

Testy te będziemy rozważać na próbkach z rozkładu Bernoulliego $S \sim \mathcal{B}(n, p)$. Estymator prawdopodobieństwa $p$ definiujemy przez stosunek liczby sukcesów do liczby prób, zatem
$$
\hat{p} = \frac{S}{n}.
$$
Dodatkowo z rozkładu wiemy, że
$$
\mathbb{E}(\hat{p}) = p, \quad \text{Var}(\hat{p}) = \frac{p(1-p)}{n}
$$
Do obliczania przedziałów ufności w R użyjemy funkcji BinomCI z pakietu DescTools.

### Przedział Wilsona
Przedział Wilsona oparty jest na normalnym przybliżeniu rozkładu Bernoulliego tzn.
$$
\frac{\hat{p}-\mathbb{E}(\hat{p})}{\sqrt{\text{Var}(\hat{p})}} \approx \mathcal{N}(0, 1) \iff
\frac{\hat{p}-p}{\sqrt{p(1-p)/n}} \approx \mathcal{N}(0, 1).
$$
Dla przedziału lewostronnego mamy:
$$
\mathbb{P}\left(\frac{\hat{p}-p}{\sqrt{p(1-p)/n}} \geq -z_{1-\alpha}\right) \approx 1 - \alpha.
$$

Lewostronny przedział Wilsona otrzymujemy rozwiązując nierówność dla $p$
$$
 \frac{\hat{p}-p}{\sqrt{p(1-p)/n}} \geq -z_{1-\alpha}
$$
Rozwiązując nierówność otrzymujemy przedział ufności $(0, U_W]$, gdzie
$$
 U_W = \frac{1}{1+ \frac{z_{1-\alpha}^2}{n}}\left(\hat{p}+\frac{z_{1-\alpha}^2}{2n} + z_{1-\alpha}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}+\frac{z_{1-\alpha}^2}{4n^2}}\right)
$$
Odrzucamy hipotezę zerową $H_0$, jeżeli $0.1 \notin (0, U_W]$ lub równoważnie $0.1 > U_W$.

### Przedział Cloppera-Pearsona
Przedział Cloppera-Pearsona oparty jest o dystrybuantę $S \sim \mathcal{B}(n, p)$, która opisana jest równaniem
$$
\mathbb{P}(S \leq s) = \sum_{k=0}^s \binom{n}{k}p^k(1-p)^{n-k},
$$
gdzie $s$ to liczba sukcesów w obserwowanej próbie. Dla przedziału lewostronnego $(0, U_{CP}]$ szukamy $U_{CP}$ spełniającego
$$
\mathbb{P}_{p=U_{CP}}(S\leq s) = 1 - \alpha,
$$
zatem górna granica $U_{CP}$ przedziału ufności  jest rozwiązaniem równania
$$
\sum_{k=0}^s \binom{n}{k}(U_{CP})^k(1-U_{CP})^{n-k} = 1 - \alpha.
$$
Alternatywnie, korzystając z relacji między rozkładem Bernoulliego a rozkładem beta przedział Cloppera-Pearsona możemy zdefiniować za pomocą kwantyli rozkładu beta, wtedy
$$
U_{CP} = \text{Beta}^{-1}(1-\alpha; s+1; n-s),
$$
gdzie $\text{Beta}^{-1}$ oznacza kwantyl rozkładu beta. Odrzucamy hipotezę zerową $H_0$, jeżeli $0.1 \notin (0, U_{CP}]$ lub równoważnie $0.1 > U_{CP}$.

### Przedział Jeffreysa
Przedział Jeffreysa oparty jest o rozkład Jeffreysa. W przypadku próby z rozkładu Bernoulliego $S \sim \mathcal{B}(n, p)$ zakładamy, że prawdopodobieństwo $p$ ma rozkład 
$$
p \sim \text{Beta}\left(\frac{1}{2}, \frac{1}{2}\right).
$$
Po zaobserwowaniu w próbie $s$ sukcesów rozkład prawdopodobieństwa wygląda następująco
$$
p | s \sim \text{Beta}\left(s+\frac{1}{2}, n - s + \frac{1}{2}  \right).
$$
Lewostronny przedział ufności $(0, U_J)$ otrzymamy obliczając kwantyl $1-\alpha$ powyższego rozkładu, zatem
$$
U_J = \text{Beta}^{-1}\left(1-\alpha, s+\frac{1}{2}, n - s + \frac{1}{2}  \right).
$$
Odrzucamy hipotezę zerową $H_0$, jeżeli $0.1 \notin (0, U_{J}]$ lub równoważnie $0.1 > U_{J}$.

### Test jednostajnie najmocniejszy
Przeprowadzany przez nas test jest niezrandomizowany, zatem funkcję mocy definiujemy następująco
$$
\beta_T(p) = \mathbb{P}_p[T(S) = 1],
$$
gdzie $T$ oznacza przeprowadzany test.

Test jest jednostajnie najmocniejszy w danej rodzinie testów przy poziomie istotności $\alpha$, jeśli jest mocniejszy lub niegorszy od dowolnego innego rozważanego testu dla wszystkich wartości zbioru hipotezy alternatywnej, czyli w naszym przypadku dla $p < 0.1$. Inaczej, test $T^*$ jest jednostajnie najmocniejszy w rodzinie testów $\mathcal{T}_\alpha$, jeżeli 
$$
\forall_{p < 0.1}\forall_{T\in\mathcal{T}_\alpha}\beta_{T^*}(p) \geq \beta_T(p).
$$

# Przeprowadzenie testów

### Testy dla $S \sim \mathcal{B}(5, p)$

### Testy dla $S \sim \mathcal{B}(30, p)$

### Testy dla $S \sim \mathcal{B}(250, p)$

# Podsumowanie