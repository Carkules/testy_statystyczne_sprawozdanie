---
title: "Sprawozdanie 2"
author: "Konrad Słotta i Kacper Łazurkiewicz"
format: pdf
editor: visual
execute:
  echo: false
  warning: false
  message: false
crossref:
  fig-title: "Rysunek"
---

# Przyjęte założenia i hipotezy

Rozważamy testy na poziomie istotności $\alpha = 0.05$ do testowania

-   $H_0: p = 0.1$, przeciwko

-   $H_1: p < 0.1$.

Będziemy wykonywać sprawdzenie tej hipotezy, stosując wprost trzy testy:

1.  testu opartego o przedział Wilsona,

2.  testu opartego o przedział Cloppera-Pearsona,

3.  testu opartego o przedział Jeffreysa.

Testy te będziemy rozważać na próbkach z rozkładu Bernoulliego $S \sim \mathcal{B}(n, p)$. Estymator prawdopodobieństwa $p$ definiujemy przez stosunek liczby sukcesów do liczby prób, zatem
$$
\hat{p} = \frac{S}{n}.
$$
Dodatkowo z rozkładu wiemy, że
$$
\mathbb{E}(\hat{p}) = p, \quad \text{Var}(\hat{p}) = \frac{p(1-p)}{n}
$$
Do obliczania przedziałów ufności w R użyjemy funkcji BinomCI z pakietu DescTools.

### Przedział Wilsona
Przedział Wilsona oparty jest na normalnym przybliżeniu rozkładu Bernoulliego tzn.
$$
\frac{\hat{p}-\mathbb{E}(\hat{p})}{\sqrt{\text{Var}(\hat{p})}} \approx \mathcal{N}(0, 1) \iff
\frac{\hat{p}-p}{\sqrt{p(1-p)/n}} \approx \mathcal{N}(0, 1).
$$
Dla przedziału lewostronnego mamy:
$$
\mathbb{P}\left(\frac{\hat{p}-p}{\sqrt{p(1-p)/n}} \geq -z_{1-\alpha}\right) \approx 1 - \alpha.
$$

Lewostronny przedział Wilsona otrzymujemy rozwiązując nierówność dla $p$
$$
 \frac{\hat{p}-p}{\sqrt{p(1-p)/n}} \geq -z_{1-\alpha}
$$
Rozwiązując nierówność otrzymujemy przedział ufności $(0, U_W]$, gdzie
$$
 U_W = \frac{1}{1+ \frac{z_{1-\alpha}^2}{n}}\left(\hat{p}+\frac{z_{1-\alpha}^2}{2n} + z_{1-\alpha}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}+\frac{z_{1-\alpha}^2}{4n^2}}\right)
$$
Odrzucamy hipotezę zerową $H_0$, jeżeli $0.1 \notin (0, U_W]$ lub równoważnie $0.1 > U_W$.

### Przedział Cloppera-Pearsona
Przedział Cloppera-Pearsona oparty jest o dystrybuantę $S \sim \mathcal{B}(n, p)$, która opisana jest równaniem
$$
\mathbb{P}(S \leq s) = \sum_{k=0}^s \binom{n}{k}p^k(1-p)^{n-k},
$$
gdzie $s$ to liczba sukcesów w obserwowanej próbie. Dla przedziału lewostronnego $(0, U_{CP}]$ szukamy $U_{CP}$ spełniającego
$$
\mathbb{P}_{p=U_{CP}}(S\leq s) = 1 - \alpha,
$$
zatem górna granica $U_{CP}$ przedziału ufności  jest rozwiązaniem równania
$$
\sum_{k=0}^s \binom{n}{k}(U_{CP})^k(1-U_{CP})^{n-k} = 1 - \alpha.
$$
Alternatywnie, korzystając z relacji między rozkładem Bernoulliego a rozkładem beta przedział Cloppera-Pearsona możemy zdefiniować za pomocą kwantyli rozkładu beta, wtedy
$$
U_{CP} = \text{Beta}^{-1}(1-\alpha; s+1; n-s),
$$
gdzie $\text{Beta}^{-1}$ oznacza kwantyl rozkładu beta. Odrzucamy hipotezę zerową $H_0$, jeżeli $0.1 \notin (0, U_{CP}]$ lub równoważnie $0.1 > U_{CP}$.

### Przedział Jeffreysa
Przedział Jeffreysa oparty jest o rozkład Jeffreysa. W przypadku próby z rozkładu Bernoulliego $S \sim \mathcal{B}(n, p)$ zakładamy, że prawdopodobieństwo $p$ ma rozkład 
$$
p \sim \text{Beta}\left(\frac{1}{2}, \frac{1}{2}\right).
$$
Po zaobserwowaniu w próbie $s$ sukcesów rozkład prawdopodobieństwa wygląda następująco
$$
p | s \sim \text{Beta}\left(s+\frac{1}{2}, n - s + \frac{1}{2}  \right).
$$
Lewostronny przedział ufności $(0, U_J)$ otrzymamy obliczając kwantyl $1-\alpha$ powyższego rozkładu, zatem
$$
U_J = \text{Beta}^{-1}\left(1-\alpha, s+\frac{1}{2}, n - s + \frac{1}{2}  \right).
$$
Odrzucamy hipotezę zerową $H_0$, jeżeli $0.1 \notin (0, U_{J}]$ lub równoważnie $0.1 > U_{J}$.

### Test jednostajnie najmocniejszy
Przeprowadzany przez nas test jest niezrandomizowany, zatem funkcję mocy definiujemy następująco
$$
\beta_T(p) = \mathbb{P}_p[T(S) = 1],
$$
gdzie $T$ oznacza przeprowadzany test. Inaczej, funkcja mocy oznacza prawdopodobieństwo odrzucenia hipotezy zerowej $H_0$.

Test jest jednostajnie najmocniejszy w danej rodzinie testów przy poziomie istotności $\alpha$, jeśli jest mocniejszy lub niegorszy od dowolnego innego rozważanego testu dla wszystkich wartości zbioru hipotezy alternatywnej, czyli w naszym przypadku dla $p < 0.1$. Inaczej, test $T^*$ jest jednostajnie najmocniejszy w rodzinie testów $\mathcal{T}_\alpha$, jeżeli 
$$
\forall_{p < 0.1}\forall_{T\in\mathcal{T}_\alpha}\beta_{T^*}(p) \geq \beta_T(p).
$$

# Przeprowadzenie testów
Teraz korzystając z symulacji Monte Carlo przeprowadzimy testy i wykonamy wykresy funkcji mocy w zależności od $p$ dla różnych wielkości próby $n$. W każdym przypadku sprawdzimy czy istnieje test jednostajnie najmocniejszy spośród rozważanych testów.
```{r}
library(DescTools)

alpha <- 0.05
Nmc   <- 1000
P_seq <- seq(0,1,0.001)

power <- function(n,P=P_seq){
  
  power_wilson <- sapply(P,function(p) {
    S <- rbinom(Nmc, size = n, prob = p)
    mean(sapply(S, function(s) {
      ci <- BinomCI(x = s, n = n, conf.level = 1-alpha, method="wilson")
      ci[,3] < 0.1
    }))
  })
  
  power_cp <- sapply(P, function(p) {
    S <- rbinom(Nmc, size = n, prob = p)
    mean(sapply(S, function(s) {
      ci <- BinomCI(x = s, n = n, conf.level = 1-alpha, method="clopper-pearson")
      ci[,3] < 0.1
    }))
  })
  
  power_jeff <- sapply(P, function(p) {
    S <- rbinom(Nmc, size = n, prob = p)
    mean(sapply(S, function(s) {
      ci <- BinomCI(x = s, n = n, conf.level = 1-alpha, method="jeffreys")
      ci[,3] < 0.1
    }))
  })
  
  list(P = P, power_wilson = power_wilson,
       power_cp = power_cp, power_jeff = power_jeff)
}

draw_power <- function(power_n, zoomx = c(0,1), zoomy = FALSE, alpha = 0.05, title="") {
  
  idx <- (power_n$P >= zoomx[1]) & (power_n$P <= zoomx[2])
  P <- power_n$P[idx]
  power_wilson <- power_n$power_wilson[idx]
  power_cp     <- power_n$power_cp[idx]
  power_jeff   <- power_n$power_jeff[idx]
  
  ylim_range <- if(zoomy) c(0, 2*alpha) else c(0,1)

  #main_text <- sprintf(title)
  
  plot(P, power_wilson, type="l", lwd=2, lty=1, col="black",
       ylim=ylim_range, xlab="p", ylab="Moc testu",
       cex.main=1, adj=0.5)
  
  lines(P, power_cp, col="red", lwd=2, lty=2)
  lines(P, power_jeff, col="blue", lwd=2, lty=4)
  
  abline(v=0.1, lty=3, col="black")  # H0
  abline(h=alpha, lty=3, col="black")    # poziom istotności
  
  legend("topright",
         legend=c("Wilson","Clopper-Pearson","Jeffreys"),
         col=c("black","red","blue"),
         lwd=2, lty=c(1,2,4))
}


kompilacja <- FALSE
wczytanie <- TRUE
zapis <- FALSE

if(kompilacja){
  power1 <- power(5)
  power2 <- power(30)
  power3 <- power(250)
} 
if(zapis&kompilacja){
  save(power1, file = "wyniki1_MC.RData")
  save(power2, file = "wyniki2_MC.RData")
  save(power3, file = "wyniki3_MC.RData")
}
if(wczytanie){
  load("wyniki1_MC.RData")
  load("wyniki2_MC.RData")
  load("wyniki3_MC.RData")
}
```
### Testy dla $S \sim \mathcal{B}(5, p)$
```{r}
#| label: fig_1
#| fig-cap: "Wykres funkcji mocy w zależności od $p$ dla $n = 5$"
#| fig-width: 7
#| fig-height: 6
draw_power(power1, zoomx=c(0,1),zoomy=TRUE)
```
Na powyższym wykresie możemy zauważyć, że moc wszystkich testów jest praktycznie równa zeru w całym zakresie $p$. Jest to zgodne z teorią, gdyż w tym przypadku pojedynczy sukces zmienia $\hat{p}$ o $0.2$. Przez to natomiast wszystkie te testy nie pozwalają na skuteczne wykrywanie efektu. Hipoteza alternatywna jest zbyt wąska, żeby ją przyjąć przy tak małej liczności próby. Na wykresie widzimy także, że dla $0 \leq p < 0.1$ wszystkie testy pokrywają się, zatem na podstawie symulacji nie jesteśmy w stanie jednoznacznie wskazać testu jednostajnie najmocniejszego.

### Testy dla $S \sim \mathcal{B}(30, p)$
```{r}
#| label: fig_2
#| fig-cap: "Wykres funkcji mocy w zależności od $p$ dla $n = 30$"
#| fig-width: 7
#| fig-height: 6
draw_power(power2, zoomx=c(0,1),zoomy=FALSE)
#draw_power(power2, zoomx=c(0,0.25),zoomy=FALSE)
#draw_power(power2, zoomx=c(0,0.25),zoomy=TRUE)
```
Dla większej liczności próby zaczynamy zauważać różnice między testami. Moc testu opartego na przedziale Jeffreysa gwałtownie maleje od $1$ do $0$. Dodatkowo, krzywa mocy tego testu w przybliżeniu zawiera punkt $(0.1, 0.05)$. Oznacza to, że $H_0$ odrzucane jest z prawdopodobieństwem $0.05$, co jest zgodne z naszym założeniem dotyczącym poziomu istotności testu. Moc testu opartego o przedział Wilsona i Cloppera-Pearsona podobnie jak dla $n = 5$ jest bliska $0$ dla każdego $p$. Oznacza to, że dla tych dwóch testów liczność próby $n$ jest ciągle zbyt mała, żeby odrzucić $H_0$.  Patrząc na wartości mocy dla $0 \leq p < 0.1$ widzimy, że moc testu opartego o przedział Jeffreysa jest większa od dwóch pozostałych testów. Stąd wnioskujemy, że w tym przypadku test oparty o przedział Jeffreysa jest jednostajnie najmocniejszy spośród rozważanych testów.

### Testy dla $S \sim \mathcal{B}(250, p)$
```{r}
#| label: fig_3
#| fig-cap: "Wykres funkcji mocy w zależności od $p$ dla $n = 250$"
#| fig-width: 7
#| fig-height: 6
draw_power(power3, zoomx=c(0,1),zoomy=FALSE)
#draw_power(power3, zoomx=c(0.08,0.15),zoomy=FALSE)
#draw_power(power3, zoomx=c(0.08,0.15),zoomy=TRUE)
```
Na powyższym wykresie widzimy, że testy oparte o przedział Wilsona i Cloppera-Pearsona także przybrały taki sam kształt jak test oparty o przedział Jeffreysa na poprzednim wykresie. Teraz moc wszystkich testów maleje od $1$ do $0$ i wszystkie zachowują przyjęty poziom istotności $\alpha = 0.05$. Krzywe pokrywają się w przybliżeniu do błędu symulacji Monte Carlo. Stąd, w tym przypadku nie jesteśmy w stanie wskazać testu jednostajnie najmocniejszego, natomiast w przeciwieństwie do przypadku $n = 5$ tutaj każdy test zwróci zgodny z założeniami wynik.

# Podsumowanie
Podsumowując analizę testów pod względem funkcji mocy możemy stwierdzić, kiedy używanie których testów daje najbardziej miarodajne wyniki.

- Dla bardzo małej liczności próby, tak jak w przypadku $n = 5$, wszystkie rozważane testy mają bardzo niską moc i są mało informatywne. Żeby uzyskać test o sensownej mocy i realnie wykrywający efekt, należy zwiększyć $n$.

- Dla trochę większej liczności próby, tak jak w przypadku $n = 30$, powinniśmy zastosować test oparty o przedział Jeffreysa, gdyż jest on jednostajnie najmocniejszy spośród rozważanych testów. Dla pozostałych testów liczność próby ciągle jest zbyt mała.

- Dla dużej liczności próby, tak jak w przypadku $n = 250$, każdy test będzie dobrym wyborem i zwróci zgodny z założeniami wynik.